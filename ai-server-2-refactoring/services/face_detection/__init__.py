# -*- coding: utf-8 -*-
"""Ear_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RGqo4ZeGTXskSbw8EurccYso_95ECwoQ
"""

# 필요한 라이브러리들 import
import cv2, os
import numpy as np
from keras.models import load_model
from utils.common import resize_img, empty_directory

img_size = 224

# 인공지능 모델 load
bbs_path = "services/face_detection/models/bbs_1.h5"
lmks_path = "services/face_detection/models/lmks_1.h5"

bbs_model = load_model(bbs_path)
lmks_model = load_model(lmks_path)

crop_path = os.path.abspath("datasets/2_crop")


def detection(file_path):
    # 폴더 비우기
    empty_directory(f"{crop_path}/*")

    # 이미지 load
    file_list = os.listdir(file_path)

    crop_list = []
    # 얼굴 인식 후 crop 및 흑백처리 후 저장
    for _, f in enumerate(file_list):
        crop_list.append(crop_dataset(f, file_path))

    # 고양이 귀 auto labeling
    for crop in crop_list:
        auto_labeling(crop)


def crop_dataset(f, file_path):
    # 파일 이름, 확장자
    filename, _ = os.path.splitext(f)

    img = cv2.imread(os.path.join(file_path, f))
    ori_img = img.copy()

    # predict cat Face
    img, ratio, top, left = resize_img(img, img_size)
    inputs = (img.astype("float32") / 255).reshape((1, img_size, img_size, 3))
    pred_bb = bbs_model.predict(inputs, verbose=0)[0].reshape((-1, 2))

    # compute cat bounding box of original image
    ori_bb = ((pred_bb - np.array([left, top])) / ratio).astype(int)

    # compute lazy bounding box for detecting landmarks
    center = np.mean(ori_bb, axis=0)
    face_size = max(np.abs(ori_bb[1] - ori_bb[0]))
    new_bb = np.array([center - face_size * 0.8, center + face_size * 0.8]).astype(int)
    new_bb = np.clip(new_bb, 0, 99999)

    # 얼굴 인식 후 크롭해 경로로 저장
    face_img = ori_img[new_bb[0][1] : new_bb[1][1], new_bb[0][0] : new_bb[1][0]]
    cv2.imwrite(f"{crop_path}/{filename}.jpg", face_img)

    return {
        "filename": filename,
        "face_img": face_img,
        "ori_img": ori_img,
        "new_bb": new_bb,
        "ori_bb": ori_bb,
    }


# 데이터셋 전처리
def auto_labeling(crop):
    (
        filename,
        face_img,
        ori_img,
        new_bb,
        ori_bb,
    ) = (
        crop["filename"],
        crop["face_img"],
        crop["ori_img"],
        crop["new_bb"],
        crop["ori_bb"],
    )

    # 귀 Auto-labeling
    # 얼굴 사진 Preprocessing
    face_img, face_ratio, face_top, face_left = resize_img(face_img, img_size)
    face_inputs = (face_img.astype("float32") / 255).reshape((1, img_size, img_size, 3))

    # 랜드마크 추출
    pred_lmks = lmks_model.predict(face_inputs, verbose=0)[0].reshape((-1, 2))

    # compute landmark of original image
    new_lmks = ((pred_lmks - np.array([face_left, face_top])) / face_ratio).astype(int)
    ori_lmks = new_lmks + new_bb[0]

    # visualizing
    cv2.rectangle(
        ori_img,
        pt1=tuple(ori_bb[0]),
        pt2=tuple(ori_bb[1]),
        color=(255, 255, 255),
        thickness=2,
    )

    # Get the coordinates of landmarks
    lmk6 = tuple(ori_lmks[6])
    lmk7 = tuple(ori_lmks[7])
    lmk8 = tuple(ori_lmks[8])

    lmk6_x, lmk6_y = lmk6[0], lmk6[1]
    lmk7_x, lmk7_y = lmk7[0], lmk7[1]
    lmk8_x, lmk8_y = lmk8[0], lmk8[1]

    # Compute the position and size of the rectangle
    x2 = min(lmk6_x, lmk7_x, lmk8_x)
    y2 = max(lmk6_y, lmk7_y, lmk8_y)
    w2 = max(lmk6_x, lmk7_x, lmk8_x) - x2
    h2 = min(lmk6_y, lmk7_y, lmk8_y) - y2

    # 1.3배 여유분
    new_w2 = w2 * 1.3
    new_h2 = h2 * 1.3
    new_pt2_x = x2 + new_w2
    new_pt2_y = y2 + new_h2

    # 여유분을 줬을 때 포인트가 이미지 밖으로 나가는거 방지
    if new_pt2_x > ori_img.shape[1]:
        # print(new_pt2_x , ori_img.shape[1])
        new_pt2_x = ori_img.shape[1] - 1
    if new_pt2_y > ori_img.shape[0]:
        # print(new_pt2_y , ori_img.shape[0])
        new_pt2_y = ori_img.shape[0] - 1

    new_w2 = new_pt2_x - x2
    new_h2 = new_pt2_y - y2

    # # visualizing
    # cv2.rectangle(ori_img, pt1=(x2, y2), pt2=(int(x2 + new_w2), int(y2 + new_h2)), color=(0, 255, 0), thickness=2)
    # cv2.imwrite('./Desktop/S08P31E203/ai/face_detection/output/%s.jpg' % (filename), ori_img)

    # save .txt file
    x_center = (x2 + new_w2 // 2) / ori_img.shape[1]
    y_center = (y2 + new_h2 // 2) / ori_img.shape[0]
    width = new_w2 / ori_img.shape[1]
    height = abs(new_h2 / ori_img.shape[0])

    data = str(x_center) + " " + str(y_center) + " " + str(width) + " " + str(height)
    with open(f"{crop_path}/{filename}.txt", "w") as file:
        file.write(data)

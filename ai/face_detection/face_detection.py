# -*- coding: utf-8 -*-
"""Ear_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RGqo4ZeGTXskSbw8EurccYso_95ECwoQ
"""

#필요한 라이브러리들 import
import cv2, os
import numpy as np
from keras.models import load_model


# 이미지 전처리 함수
def resize_img(im):
  old_size = im.shape[:2] # old_size is in (height, width) format
  ratio = float(img_size) / max(old_size)
  new_size = tuple([int(x*ratio) for x in old_size])
  # new_size should be in (width, height) format
  im = cv2.resize(im, (new_size[1], new_size[0]))
  delta_w = img_size - new_size[1]
  delta_h = img_size - new_size[0]
  top, bottom = delta_h // 2, delta_h - (delta_h // 2)
  left, right = delta_w // 2, delta_w - (delta_w // 2)
  new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,
      value=[0, 0, 0])
  return new_im, ratio, top, left


# 이미지 load
print('hi',os.getcwd())
print('hi',os.path.abspath('./input'))
base_path = os.path.abspath('./input')
file_list = sorted(os.listdir(base_path))
img = cv2.imread(os.path.join(base_path, file_list[0]))
ori_img = img.copy()

img_size = 224


# 인공지능 모델 load

bbs_path = './models/bbs_1.h5'
lmks_path = './models/lmks_1.h5'

bbs_model = load_model(bbs_path)
lmks_model = load_model(lmks_path)

# 얼굴 인식 후 crop 및 흑백처리 후 저장

for index, f in enumerate(file_list):
  # 파일 이름, 확장자
  filename, ext = os.path.splitext(f)

  img = cv2.imread(os.path.join(base_path, f))
  ori_img = img.copy()
  result_img = img.copy()

  # predict cat Face
  img, ratio, top, left = resize_img(img)
  inputs = (img.astype('float32') / 255).reshape((1, img_size, img_size, 3))
  pred_bb = bbs_model.predict(inputs)[0].reshape((-1, 2))

  # compute cat bounding box of original image
  ori_bb = ((pred_bb - np.array([left, top])) / ratio).astype(int)

  # compute lazy bounding box for detecting landmarks
  center = np.mean(ori_bb, axis=0)
  face_size = max(np.abs(ori_bb[1] - ori_bb[0]))
  new_bb = np.array([
    center - face_size * 0.6,
    center + face_size * 0.6
  ]).astype(int)
  new_bb = np.clip(new_bb, 0, 99999)

  # 얼굴 인식 후 크롭해 경로로 저장
  face_img = ori_img[new_bb[0][1]:new_bb[1][1], new_bb[0][0]:new_bb[1][0]]
  cv2.imwrite('../image_clustering/input/%s.jpg' % (filename), face_img)

  # 귀 Auto-labeling
  # 얼굴 사진 Preprocessing
  face_img, face_ratio, face_top, face_left = resize_img(face_img)
  face_inputs = (face_img.astype('float32') / 255).reshape((1, img_size, img_size, 3))
  
  #랜드마크 추출
  pred_lmks = lmks_model.predict(face_inputs)[0].reshape((-1, 2))

  # compute landmark of original image
  new_lmks = ((pred_lmks - np.array([face_left, face_top])) / face_ratio).astype(int)
  ori_lmks = new_lmks + new_bb[0]

  # visualizing
  cv2.rectangle(ori_img, pt1=tuple(ori_bb[0]), pt2=tuple(ori_bb[1]), color=(255, 255, 255), thickness=2)

  # Get the coordinates of landmarks 
  lmk6 = tuple(ori_lmks[6])
  lmk7 = tuple(ori_lmks[7])
  lmk8 = tuple(ori_lmks[8])

  lmk6_x , lmk6_y = lmk6[0], lmk6[1]
  lmk7_x , lmk7_y = lmk7[0], lmk7[1]
  lmk8_x , lmk8_y = lmk8[0], lmk8[1]

  # Compute the position and size of the rectangle
  x2 = min(lmk6_x, lmk7_x, lmk8_x)
  y2 = max(lmk6_y, lmk7_y, lmk8_y)
  w2 = max(lmk6_x, lmk7_x, lmk8_x) - x2
  h2 = min(lmk6_y, lmk7_y, lmk8_y) - y2

  #1.3배 여유분
  new_w2 = w2 * 1.3
  new_h2 = h2 * 1.3
  new_pt2_x = x2 + new_w2
  new_pt2_y = y2 + new_h2

  # 여유분을 줬을 때 포인트가 이미지 밖으로 나가는거 방지
  if new_pt2_x > ori_img.shape[1] :
    print(new_pt2_x , ori_img.shape[1])
    new_pt2_x = ori_img.shape[1]-1
  if new_pt2_y > ori_img.shape[0] :
    print(new_pt2_y , ori_img.shape[0])
    new_pt2_y = ori_img.shape[0]-1
  
  new_w2 = new_pt2_x - x2 
  new_h2 = new_pt2_y - y2

  # # visualizing
  # cv2.rectangle(ori_img, pt1=(x2, y2), pt2=(int(x2 + new_w2), int(y2 + new_h2)), color=(0, 255, 0), thickness=2)
  # cv2.imwrite('./Desktop/S08P31E203/ai/face_detection/output/%s.jpg' % (filename), ori_img)

  #save .txt file
  x_center = (x2 + new_w2 // 2) / ori_img.shape[1]
  y_center = (y2 + new_h2 // 2) / ori_img.shape[0]
  width = new_w2 / ori_img.shape[1]
  height = abs(new_h2 / ori_img.shape[0])

  # data = str(x_center) + ' ' + str(y_center) + ' ' + str(width) + ' ' + str(height)
  # with open('../tnr_filtering/input/%s.txt' % (filename), 'w') as file:
  #   file.write(data)


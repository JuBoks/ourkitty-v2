# -*- coding: utf-8 -*-
"""Image_Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uBdctGmBuAQIOGf7Y_Vg-ho7NnJ9j_7-
"""

import os
import numpy as np
import cv2
import random
import tensorflow as tf
import sklearn
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import euclidean_distances
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input
import matplotlib.pyplot as plt
from matplotlib.offsetbox import OffsetImage, AnnotationBbox

img_size = 224
base_path = os.path.abspath('./Desktop/S08P31E203/ai/image_clustering/input')
file_list = sorted(os.listdir(base_path))
random.shuffle(file_list)

# 이미지 전처리 함수
def resize_img(im):
  old_size = im.shape[:2] # old_size is in (height, width) format
  ratio = float(img_size) / max(old_size)
  new_size = tuple([int(x*ratio) for x in old_size])
  # new_size should be in (width, height) format
  im = cv2.resize(im, (new_size[1], new_size[0]))
  delta_w = img_size - new_size[1]
  delta_h = img_size - new_size[0]
  top, bottom = delta_h // 2, delta_h - (delta_h // 2)
  left, right = delta_w // 2, delta_w - (delta_w // 2)
  new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])
  return new_im, ratio, top, left

def extract_features(directory):
    # Load the MobileNet model
    model = MobileNet(weights='imagenet', include_top=False)

    features = []
    for img_name in os.listdir(directory):
        
        # Check if the file is a valid image file
        if os.path.splitext(img_name)[1].lower() not in ('.jpg'):
            continue

        # Load the image and preprocess it
        img_path = os.path.join(directory, img_name)
        img = cv2.imread(img_path)
        img, ratio, top, left = resize_img(img)        
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)

        # Extract features using the MobileNet model
        features.append(model.predict(x).ravel())

    return np.array(features)

def calculate_num_of_cluster(features):
    # Determine the optimal number of clusters using the elbow method
    start = 1
    end = 11
    wcss = []
    for i in range(start, end):
        kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
        kmeans.fit(features)
        wcss.append(kmeans.inertia_)
    plt.plot(range(start, end), wcss, marker='o')
    plt.title('Elbow Method')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()

    delta_wcss = [0] + [abs(wcss[i]-wcss[i-1]) for i, _ in enumerate(wcss) if i > 0]

    elbow_point = 1
    flag = 0
    for i, _ in enumerate(delta_wcss[elbow_point:-1], elbow_point):
        a = delta_wcss[i]
        b = delta_wcss[i+1]
        result = a / b
        if result > flag:
            flag = result
        else:
            elbow_point = i - 1
            break
    
    num_of_cluster = elbow_point+start

    return num_of_cluster

def cluster_images(directory):

    features = extract_features(directory)

    num_clusters = calculate_num_of_cluster(features) + 1

    print('num_clusters :', num_clusters)

    kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(features)

    # Get the centroids
    centroids = kmeans.cluster_centers_

    # Find the representative image for each cluster
    representative_images = []
    image_paths = [os.path.join(directory, img_name) for img_name in os.listdir(directory)]
    for i, img_path in enumerate(image_paths):
        img_name = os.path.basename(img_path)
        distances = euclidean_distances(features[i].reshape(1, -1), centroids)
        closest_centroid = np.argmin(distances)
        if len(representative_images) < num_clusters:
            # Add the first image for this centroid
            representative_images.append((closest_centroid, img_name))
        elif distances[0, closest_centroid] < distances[0, representative_images[closest_centroid][0]]:
            # Replace the current representative image with a closer one
            representative_images[closest_centroid] = (closest_centroid, img_name)

    # Print the representative images for each cluster
    for i in range(num_clusters):
        print(f"Cluster {i}: {representative_images[i][1]}")

    # Reduce the dimensionality of the features to 2 dimensions using PCA
    pca = PCA(n_components=2)
    pca_features = pca.fit_transform(features)

    # Plot the clusters using a scatter plot with annotated data points
    fig, ax = plt.subplots()
    scatter = ax.scatter(pca_features[:, 0], pca_features[:, 1], c=kmeans.labels_, cmap='rainbow')
    ax.set_xlabel('Principal Component 1')
    ax.set_ylabel('Principal Component 2')

    # Annotate each data point with its corresponding image name
    for i, img_path in enumerate(image_paths):
        img_name = os.path.basename(img_path)
        ax.annotate(img_name, (pca_features[i, 0], pca_features[i, 1]))
    plt.show()

    # Plot the clusters using a scatter plot with annotated data points and images
    fig, ax = plt.subplots()
    scatter = ax.scatter(pca_features[:, 0], pca_features[:, 1], c=kmeans.labels_, cmap='rainbow')
    ax.set_xlabel('Principal Component 1')
    ax.set_ylabel('Principal Component 2')

    # Annotate each data point with its corresponding image
    for i, filename in enumerate(os.listdir(directory)):
        img = cv2.imread(os.path.join(directory, filename))
        resized_img = cv2.resize(img, (50,50)) # resize the grayscale image
        imagebox = OffsetImage(resized_img, zoom=0.5)
        ab = AnnotationBbox(imagebox, (pca_features[i, 0], pca_features[i, 1]), pad=0, frameon=False)
        ax.add_artist(ab)
    plt.show()

    # Code for Visualizing in Web-Front-End

    
    # Fiding Width, Height
    x_max = 0
    x_min = 0
    y_max = 0
    y_min = 0

    for i in range(len(pca_features[:, 1])):
      if pca_features[i][0] > x_max :
        x_max = pca_features[i][0]
      if pca_features[i][0] < x_min :
        x_min = pca_features[i][0]
      if pca_features[i][1] > y_max :
        y_max = pca_features[i][1]
      if pca_features[i][1] < y_min :
        y_min = pca_features[i][1]
    
    width = abs(x_max - x_min)
    height = abs(y_max - y_min)

    #file name , class number, x value, y value append
    file_feature_info = []
    for i, img_path in enumerate(image_paths):
        img_name = os.path.basename(img_path)
        file_feature_info.append([img_name, kmeans.labels_[i], pca_features[i, 0] + abs(x_min) , pca_features[i, 1] + abs(y_min)])
    

    return num_clusters, representative_images, width, height, file_feature_info

cluster_images(base_path)